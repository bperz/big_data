{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resources/Quo_vadis.txt\", encoding=\"utf8\") as myfile:\n",
    "    data = \" \".join(line.rstrip() for line in myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resources/polish_stopwords.txt\", encoding=\"utf8\") as myfile:\n",
    "    stop_text = \" \".join(line.rstrip() for line in myfile)\n",
    "\n",
    "stopWords = set(stop_text.split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = re.sub(r\"  [A-Z]  \", \"Rozdział\", data)\n",
    "text = re.sub(r\"[^\\w]+\", \" \", data).split(\" \")\n",
    "\n",
    "chapters = [[]]\n",
    "\n",
    "i = 0\n",
    "\n",
    "for word in text:\n",
    "    if word == \"Rozdział\":\n",
    "        chapters.append([])\n",
    "        i += 1\n",
    "        \n",
    "    else:\n",
    "        if word not in stopWords and len(word) > 1 and word[0] != \"'\":\n",
    "            chapters[i].append(word.lower())\n",
    "    \n",
    "print(chapters[1])\n",
    "chapters = chapters[1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_all_chapters = {}\n",
    "for word in [word for chapter in chapters for word in chapter]:\n",
    "    count_all_chapters.setdefault(word, 0)\n",
    "    count_all_chapters[word] = count_all_chapters[word] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_tfs = []\n",
    "chapters_word_counts = []\n",
    "book_word_counts = {}\n",
    "\n",
    "for chapter in chapters[1:]:\n",
    "    chapter_count = {}\n",
    "    total = len(chapter)\n",
    "    \n",
    "    for word in chapter:\n",
    "        chapter_count.setdefault(word, 0)\n",
    "        chapter_count[word] = chapter_count[word] + 1\n",
    "        \n",
    "        book_word_counts.setdefault(word, 0)\n",
    "        book_word_counts[word] = book_word_counts[word] + 1\n",
    "        \n",
    "    chapters_word_counts.append(chapter_count)     \n",
    "    chapters_tfs.append({word:(count/total) for (word, count) in chapter_count.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_tf_idfs = []\n",
    "\n",
    "for chapter_tf in chapters_tfs:\n",
    "    chapter_tf_idf = {}\n",
    "    for word, tf in chapter_tf.items():\n",
    "        docs_with_term = np.sum([1 for chap in chapters_tfs if word in chap.keys()])\n",
    "        chapter_tf_idf.setdefault(word, tf*np.log(len(chapters_tfs)/docs_with_term))\n",
    "    \n",
    "    chapters_tf_idfs.append(chapter_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted([x for x in chapters_tf_idfs[13].items()], key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_word_cloud(chapter, number_of_chapter=0, name=\"\"): \n",
    "    \n",
    "    if 'results' not in os.listdir():\n",
    "        os.mkdir('results')\n",
    "    \n",
    "    # in windows change to \\\\\n",
    "    path = os.getcwd() + '/results'\n",
    "    counts_list = [(word, c) for word, c in zip(chapter.keys(), chapter.values())]\n",
    "    counts_list.sort(key = lambda x: x[1], reverse=True)\n",
    "    wc_dict = {w: c for w,c in counts_list[:64]}\n",
    "    mask = np.array(Image.open(\"resources/storm.png\"))\n",
    "    cloud = WordCloud(background_color=\"white\", mask=mask, max_words=100)\n",
    "    cloud.generate_from_frequencies(wc_dict)\n",
    "    plt.imshow(cloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    if name == \"\":\n",
    "        cloud.to_file(\"{}/chapter_{}_cloud.png\".format(path, number_of_chapter))\n",
    "    else:\n",
    "        cloud.to_file(\"{}/{}.png\".format(path, name))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chap_n, chapter in enumerate(chapters_word_counts):\n",
    "    save_word_cloud(chapter, chap_n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_word_cloud(book_word_counts, name='whole_book')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_highest_tf_idfs = []\n",
    "\n",
    "for chapter in chapters_tf_idfs:\n",
    "    chap_words = [item for item in chapter.items()]\n",
    "    chapters_highest_tf_idfs.append(sorted(chap_words, key=lambda x: x[1], reverse=True)[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chapters_highest_tf_idfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chapters(word, chapters):\n",
    "    chaps_list = []\n",
    "    for i,chapter in enumerate(chapters):\n",
    "        chaps_list.append((i, chapter.get(word.lower(), 0)))\n",
    "    \n",
    "    return sorted(chaps_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_chapters(\"cezar\", chapters_tf_idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
